{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IxevrpjX7he"
      },
      "source": [
        "# EBAC - Regress√£o II - regress√£o m√∫ltipla\n",
        "\n",
        "## Tarefa I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjryA0_CX7hg"
      },
      "source": [
        "#### Previs√£o de renda II\n",
        "\n",
        "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que √© a base do seu pr√≥ximo projeto. Vamos usar os recursos que vimos at√© aqui nesta base.\n",
        "\n",
        "|variavel|descri√ß√£o|\n",
        "|-|-|\n",
        "|data_ref                | Data de refer√™ncia de coleta das vari√°veis |\n",
        "|index                   | C√≥digo de identifica√ß√£o do cliente|\n",
        "|sexo                    | Sexo do cliente|\n",
        "|posse_de_veiculo        | Indica se o cliente possui ve√≠culo|\n",
        "|posse_de_imovel         | Indica se o cliente possui im√≥vel|\n",
        "|qtd_filhos              | Quantidade de filhos do cliente|\n",
        "|tipo_renda              | Tipo de renda do cliente|\n",
        "|educacao                | Grau de instru√ß√£o do cliente|\n",
        "|estado_civil            | Estado civil do cliente|\n",
        "|tipo_residencia         | Tipo de resid√™ncia do cliente (pr√≥pria, alugada etc)|\n",
        "|idade                   | Idade do cliente|\n",
        "|tempo_emprego           | Tempo no emprego atual|\n",
        "|qt_pessoas_residencia   | Quantidade de pessoas que moram na resid√™ncia|\n",
        "|renda                   | Renda em reais|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "VA0Aj55hX7hh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Lasso\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "VKhtoqyXX7hh"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('previsao_de_renda.csv')\n",
        "data = pd.DataFrame(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hIGzr0UX7hh",
        "outputId": "9ad304c6-19a3-4514-fd9e-b1b453a2e497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15000 entries, 0 to 14999\n",
            "Data columns (total 15 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   Unnamed: 0             15000 non-null  int64  \n",
            " 1   data_ref               15000 non-null  object \n",
            " 2   id_cliente             15000 non-null  int64  \n",
            " 3   sexo                   15000 non-null  object \n",
            " 4   posse_de_veiculo       15000 non-null  bool   \n",
            " 5   posse_de_imovel        15000 non-null  bool   \n",
            " 6   qtd_filhos             15000 non-null  int64  \n",
            " 7   tipo_renda             15000 non-null  object \n",
            " 8   educacao               15000 non-null  object \n",
            " 9   estado_civil           15000 non-null  object \n",
            " 10  tipo_residencia        15000 non-null  object \n",
            " 11  idade                  15000 non-null  int64  \n",
            " 12  tempo_emprego          12427 non-null  float64\n",
            " 13  qt_pessoas_residencia  15000 non-null  float64\n",
            " 14  renda                  15000 non-null  float64\n",
            "dtypes: bool(2), float64(3), int64(4), object(6)\n",
            "memory usage: 1.5+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3jAB1OUX7hi"
      },
      "source": [
        "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
        "2. Rode uma regulariza√ß√£o *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
        "3. Fa√ßa o mesmo que no passo 2, com uma regress√£o *LASSO*. Qual m√©todo chega a um melhor resultado?\n",
        "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
        "5. Compare os par√¢metros e avalie eventuais diferen√ßas. Qual modelo voc√™ acha o melhor de todos?\n",
        "6. Partindo dos modelos que voc√™ ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transforma√ß√£o ou combina√ß√£o de vari√°veis.\n",
        "7. Ajuste uma √°rvore de regress√£o e veja se consegue um $R^2$ melhor com ela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fStgJ-WX7hi",
        "outputId": "32c20879-b709-48ae-c924-6a469451251d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treinamento: (11250, 14)\n",
            "Tamanho do conjunto de teste: (3750, 14)\n"
          ]
        }
      ],
      "source": [
        "#1\n",
        "\n",
        "# Garantir que X e y sejam num√©ricos\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "y = pd.to_numeric(y, errors='coerce')\n",
        "\n",
        "# Vari√°veis independentes (X) e dependente (y)\n",
        "X = df.drop('renda', axis=1)\n",
        "y = df['renda']\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste (75% para treinamento, 25% para teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "# Verificar o tamanho dos conjuntos\n",
        "print(\"Tamanho do conjunto de treinamento:\", X_train.shape)\n",
        "print(\"Tamanho do conjunto de teste:\", X_test.shape)"
      ]
    },
    {
      "source": [
        "#2\n",
        "\n",
        "# Preencher valores nulos\n",
        "df['tempo_emprego'].fillna(df['tempo_emprego'].median(), inplace=True)\n",
        "\n",
        "# Codifica√ß√£o das vari√°veis categ√≥ricas\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Dividir os dados em vari√°veis independentes (X) e dependente (y)\n",
        "X = df.drop('renda', axis=1)\n",
        "y = df['renda']\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste (75% treinamento, 25% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Valores de alpha para testar\n",
        "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "r2_scores = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    # Criar e treinar o modelo Ridge\n",
        "    model = Ridge(alpha=alpha)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Fazer previs√µes na base de teste\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Avaliar o modelo com o R¬≤\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Exibir os resultados\n",
        "for alpha, r2 in zip(alphas, r2_scores):\n",
        "    print(f'Alpha: {alpha}, R¬≤ Score: {r2}')\n",
        "\n",
        "# Encontrar o melhor alpha com base no R¬≤\n",
        "best_alpha = alphas[np.argmax(r2_scores)]\n",
        "best_r2 = max(r2_scores)\n",
        "\n",
        "print(f'Melhor alpha: {best_alpha} com R¬≤ Score: {best_r2}')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl6i_NaAbB-x",
        "outputId": "c6229518-11a6-4953-db4e-1a0a979b4559"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha: 0, R¬≤ Score: 0.26802204227884163\n",
            "Alpha: 0.001, R¬≤ Score: 0.26802204633430404\n",
            "Alpha: 0.005, R¬≤ Score: 0.2680220609254066\n",
            "Alpha: 0.01, R¬≤ Score: 0.2680220755752635\n",
            "Alpha: 0.05, R¬≤ Score: 0.2680220637071694\n",
            "Alpha: 0.1, R¬≤ Score: 0.26802178629490303\n",
            "Melhor alpha: 0.01 com R¬≤ Score: 0.2680220755752635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-97-c74c07a90982>:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['tempo_emprego'].fillna(df['tempo_emprego'].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "\n",
        "# Valores de alpha para testar\n",
        "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "r2_scores_lasso = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    # Criar e treinar o modelo LASSO\n",
        "    model = Lasso(alpha=alpha)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Fazer previs√µes na base de teste\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Avaliar o modelo com o R¬≤\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores_lasso.append(r2)\n",
        "\n",
        "# Exibir os resultados\n",
        "for alpha, r2 in zip(alphas, r2_scores_lasso):\n",
        "    print(f'Alpha: {alpha}, R¬≤ Score: {r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amYyEa-gej-C",
        "outputId": "f55feaf8-2b16-458d-841a-735acec67ec5"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.855e+11, tolerance: 7.723e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.855e+11, tolerance: 7.723e+07\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.855e+11, tolerance: 7.723e+07\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.855e+11, tolerance: 7.723e+07\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.855e+11, tolerance: 7.723e+07\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha: 0, R¬≤ Score: 0.26802029222505375\n",
            "Alpha: 0.001, R¬≤ Score: 0.26802027212645974\n",
            "Alpha: 0.005, R¬≤ Score: 0.2680201579239637\n",
            "Alpha: 0.01, R¬≤ Score: 0.2680199389911513\n",
            "Alpha: 0.05, R¬≤ Score: 0.2680151506637477\n",
            "Alpha: 0.1, R¬≤ Score: 0.2680016177634079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.854e+11, tolerance: 7.723e+07\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultados da regulariza√ß√£o Ridge\n",
        "r2_scores_ridge = [0.26802204227884163, 0.26802204633430404, 0.2680220609254066, 0.2680220755752635, 0.2680220637071694, 0.26802178629490303]\n",
        "\n",
        "# Comparar os melhores modelos\n",
        "best_alpha_ridge = alphas[np.argmax(r2_scores_ridge)]\n",
        "best_r2_ridge = max(r2_scores_ridge)\n",
        "\n",
        "best_alpha_lasso = alphas[np.argmax(r2_scores_lasso)]\n",
        "best_r2_lasso = max(r2_scores_lasso)\n",
        "\n",
        "print(f'Melhor alpha Ridge: {best_alpha_ridge} com R¬≤ Score: {best_r2_ridge}')\n",
        "print(f'Melhor alpha LASSO: {best_alpha_lasso} com R¬≤ Score: {best_r2_lasso}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtHXEUJ9fSxD",
        "outputId": "9112080c-e869-410c-c1d6-d851a08032bd"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhor alpha Ridge: 0.01 com R¬≤ Score: 0.2680220755752635\n",
            "Melhor alpha LASSO: 0 com R¬≤ Score: 0.26802029222505375\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#4\n",
        "\n",
        "def stepwise_selection(X, y,\n",
        "                       initial_list=[],\n",
        "                       threshold_in=0.01,\n",
        "                       threshold_out=0.05,\n",
        "                       verbose=True):\n",
        "    \"\"\"\n",
        "    Performs stepwise regression to select features.\n",
        "\n",
        "    Args:\n",
        "        X (pd.DataFrame): The independent variables.\n",
        "        y (pd.Series): The dependent variable.\n",
        "        initial_list (list): An initial list of features to include.\n",
        "        threshold_in (float): The p-value threshold for adding a feature.\n",
        "        threshold_out (float): The p-value threshold for removing a feature.\n",
        "        verbose (bool): Whether to print the steps of the selection.\n",
        "\n",
        "    Returns:\n",
        "        list: The list of selected features.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure all columns in X are numeric\n",
        "    # This is crucial for statsmodels compatibility\n",
        "    X = X.select_dtypes(include=np.number)\n",
        "\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed = False\n",
        "        # Forward step\n",
        "        excluded = list(set(X.columns) - set(included))\n",
        "        new_pval = pd.Series(index=excluded)\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
        "            new_pval[new_column] = model.pvalues[new_column]\n",
        "        best_pval = new_pval.min()\n",
        "        if best_pval < threshold_in:\n",
        "            best_feature = new_pval.idxmin()\n",
        "            included.append(best_feature)\n",
        "            changed = True\n",
        "            if verbose:\n",
        "                print(f'Add  {best_feature:30} with p-value {best_pval:.6}')\n",
        "\n",
        "        # Backward step\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        # Use all coefs except intercept\n",
        "        pvalues = model.pvalues.iloc[1:]\n",
        "        worst_pval = pvalues.max()  # Null if pvalues is empty\n",
        "        if worst_pval > threshold_out:\n",
        "            changed = True\n",
        "            worst_feature = pvalues.idxmax()\n",
        "            included.remove(worst_feature)\n",
        "            if verbose:\n",
        "                print(f'Drop {worst_feature:30} with p-value {worst_pval:.6}')\n",
        "        if not changed:\n",
        "            break\n",
        "    return included"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "itonA5mFw8vE"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = stepwise_selection(X_train, y_train)\n",
        "print('recursos resultantes:')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDS2qI3hxE6o",
        "outputId": "8e942dd1-514c-4987-bc1b-70a7dbb026df"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add  tempo_emprego                  with p-value 0.0\n",
            "Add  qt_pessoas_residencia          with p-value 1.75831e-12\n",
            "Add  qtd_filhos                     with p-value 0.000908728\n",
            "Add  idade                          with p-value 0.000251356\n",
            "recursos resultantes:\n",
            "['tempo_emprego', 'qt_pessoas_residencia', 'qtd_filhos', 'idade']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar e treinar o modelo com as vari√°veis selecionadas\n",
        "X_train_stepwise = X_train[result]\n",
        "X_test_stepwise = X_test[result]\n",
        "\n",
        "model = sm.OLS(y_train, sm.add_constant(X_train_stepwise)).fit()\n",
        "\n",
        "# Fazer previs√µes na base de teste\n",
        "y_pred_stepwise = model.predict(sm.add_constant(X_test_stepwise))\n",
        "\n",
        "# Avaliar o modelo com o R¬≤\n",
        "r2_stepwise = r2_score(y_test, y_pred_stepwise)\n",
        "\n",
        "print(f'R¬≤ Score com Stepwise: {r2_stepwise}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9BKVs0CxcBJ",
        "outputId": "12808f58-167c-4a17-bc4a-85dcbffaf83e"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R¬≤ Score com Stepwise: 0.1546641272297311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo Ridge com alpha = 0.01 teve o melhor desempenho, com um\n",
        "ùëÖ\n",
        "2\n",
        " de 0.268. Ele foi melhor que os modelos LASSO e Stepwise."
      ],
      "metadata": {
        "id": "v1YwIzh0yS3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "ridge_model = Ridge(alpha=0.01)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "ridge_coefs = pd.Series(ridge_model.coef_, index=X_train.columns)\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso_model = Lasso(alpha=0)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "lasso_coefs = pd.Series(lasso_model.coef_, index=X_train.columns)\n",
        "\n",
        "import statsmodels.api as sm\n",
        "stepwise_features = stepwise_selection(X_train, y_train)\n",
        "X_train_stepwise = X_train[stepwise_features]\n",
        "X_test_stepwise = X_test[stepwise_features]\n",
        "stepwise_model = sm.OLS(y_train, sm.add_constant(X_train_stepwise)).fit()\n",
        "stepwise_coefs = stepwise_model.params\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LsHgl-AyWoz",
        "outputId": "f2f2d26b-54f4-4351-bbc0-cc82a45e7020"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.855e+11, tolerance: 7.723e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add  tempo_emprego                  with p-value 0.0\n",
            "Add  qt_pessoas_residencia          with p-value 1.75831e-12\n",
            "Add  qtd_filhos                     with p-value 0.000908728\n",
            "Add  idade                          with p-value 0.000251356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df = pd.DataFrame({\n",
        "    'Ridge': ridge_coefs,\n",
        "    'LASSO': lasso_coefs,\n",
        "    'Stepwise': stepwise_coefs\n",
        "})\n",
        "print(comparison_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnGZGJ0sy4Fc",
        "outputId": "0dc8f9b4-2eaa-4eb9-a556-16ad7ff384c6"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     Ridge        LASSO     Stepwise\n",
            "Unnamed: 0                       -0.204916    -0.177992          NaN\n",
            "const                                  NaN          NaN   864.470144\n",
            "data_ref_2015-02-01             225.258953   194.765104          NaN\n",
            "data_ref_2015-03-01             700.651233   643.288287          NaN\n",
            "data_ref_2015-04-01            1178.874929  1094.720252          NaN\n",
            "data_ref_2015-05-01            1049.641831   938.430222          NaN\n",
            "data_ref_2015-06-01            1608.678167  1470.825072          NaN\n",
            "data_ref_2015-07-01            1499.102341  1334.004416          NaN\n",
            "data_ref_2015-08-01            1706.859263  1515.132048          NaN\n",
            "data_ref_2015-09-01            1928.064140  1709.436748          NaN\n",
            "data_ref_2015-10-01            1944.179600  1698.684154          NaN\n",
            "data_ref_2015-11-01            2373.367392  2100.825708          NaN\n",
            "data_ref_2015-12-01            3054.730604  2755.461903          NaN\n",
            "data_ref_2016-01-01            2782.695909  2456.349932          NaN\n",
            "data_ref_2016-02-01            2653.572355  2300.455855          NaN\n",
            "data_ref_2016-03-01            2959.071562  2579.290377          NaN\n",
            "educacao_P√≥s gradua√ß√£o         1002.933178  1002.050343          NaN\n",
            "educacao_Secund√°rio              98.104470    98.632444          NaN\n",
            "educacao_Superior completo      737.030582   737.719918          NaN\n",
            "educacao_Superior incompleto   -405.118015  -404.098903          NaN\n",
            "estado_civil_Separado           999.732438   990.713893          NaN\n",
            "estado_civil_Solteiro           637.597692   628.887819          NaN\n",
            "estado_civil_Uni√£o             -305.297039  -305.398954          NaN\n",
            "estado_civil_Vi√∫vo             1080.761103  1072.129692          NaN\n",
            "id_cliente                        0.007752     0.007728          NaN\n",
            "idade                            35.273118    35.283850   -25.367754\n",
            "posse_de_imovel                 299.754932   299.942956          NaN\n",
            "posse_de_veiculo                  3.964327     4.110575          NaN\n",
            "qt_pessoas_residencia          1130.791119  1122.026650  1045.194616\n",
            "qtd_filhos                    -1034.125636 -1025.355352  -809.065618\n",
            "sexo_M                         5844.475210  5844.275517          NaN\n",
            "tempo_emprego                   551.777305   551.778925   529.253986\n",
            "tipo_renda_Bolsista           -1003.231038 -1002.130481          NaN\n",
            "tipo_renda_Empres√°rio           868.270457   868.253957          NaN\n",
            "tipo_renda_Pensionista         -475.424029  -475.783444          NaN\n",
            "tipo_renda_Servidor p√∫blico      87.806986    87.500806          NaN\n",
            "tipo_residencia_Casa           -160.289143  -160.999165          NaN\n",
            "tipo_residencia_Com os pais    -186.058022  -187.083149          NaN\n",
            "tipo_residencia_Comunit√°rio    -337.662845  -339.352154          NaN\n",
            "tipo_residencia_Est√∫dio         874.612826   872.822099          NaN\n",
            "tipo_residencia_Governamental   610.038384   610.124824          NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avalia√ß√£o dos Modelos\n",
        "\n",
        "Modelo Ridge:\n",
        "\n",
        "Maior\n",
        "ùëÖ\n",
        "2\n",
        "R\n",
        "2\n",
        " : 0,2680\n",
        "Usa regulariza√ß√£o para evitar overfitting, distribuindo os pesos suavemente entre as vari√°veis.\n",
        "\n",
        "Modelo LASSO:\n",
        "\n",
        "ùëÖ\n",
        "2\n",
        "R\n",
        "2\n",
        "  um pouco menor que o Ridge: 0,2680\n",
        "Tamb√©m usa regulariza√ß√£o, mas zera muitos coeficientes, tornando o modelo mais simples.\n",
        "\n",
        "Modelo Stepwise:\n",
        "\n",
        "Menor\n",
        "ùëÖ\n",
        "2\n",
        "R\n",
        "2\n",
        " : 0,1547\n",
        "Seleciona vari√°veis passo a passo, mas √© menos robusto que os m√©todos de regulariza√ß√£o.\n",
        "\n",
        "Conclus√£o\n",
        "\n",
        "O modelo Ridge (\n",
        "ùõº\n",
        "=\n",
        "0\n",
        ",\n",
        "01\n",
        "Œ±=0,01) teve o melhor desempenho (\n",
        "ùëÖ\n",
        "2\n",
        "=\n",
        "0\n",
        ",\n",
        "2680\n",
        "R\n",
        "2\n",
        " =0,2680), equilibrando bem o uso das vari√°veis sem zerar muitos coeficientes. Por isso, √© o mais indicado para este conjunto de dados."
      ],
      "metadata": {
        "id": "BSx6EsIOzKW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "\n",
        "# Aplicar transforma√ß√µes logar√≠tmicas onde faz sentido\n",
        "X_train['log_tempo_emprego'] = np.log1p(X_train['tempo_emprego'])\n",
        "X_test['log_tempo_emprego'] = np.log1p(X_test['tempo_emprego'])\n",
        "\n",
        "# Criar vari√°veis interativas e polinomiais\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Normalizar as vari√°veis\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_poly)\n",
        "X_test_scaled = scaler.transform(X_test_poly)\n",
        "\n",
        "# Treinar e avaliar o modelo Ridge com as novas transforma√ß√µes\n",
        "ridge_model = Ridge(alpha=0.01)\n",
        "ridge_model.fit(X_train_scaled, y_train)\n",
        "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o modelo com o R¬≤\n",
        "r2_transformed_ridge = r2_score(y_test, y_pred_ridge)\n",
        "print(f'R¬≤ Score com Ridge (transformado): {r2_transformed_ridge}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugKaLI2G1p9j",
        "outputId": "79d8baaa-a942-4c7e-b797-d3fb54965e54"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R¬≤ Score com Ridge (transformado): 0.3074348447081805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A transforma√ß√£o e a normaliza√ß√£o das vari√°veis resultaram em uma melhora significativa no\n",
        "ùëÖ\n",
        "2\n",
        ". O modelo Ridge com as transforma√ß√µes aplicadas conseguiu um\n",
        "ùëÖ\n",
        "2\n",
        " de 0.307, o que √© um avan√ßo consider√°vel em compara√ß√£o com os valores anteriores.\n",
        "\n",
        "Compara√ß√£o Final dos Resultados\n",
        "Modelo Ridge (sem transforma√ß√µes):\n",
        "\n",
        "Melhor\n",
        "ùëÖ\n",
        "2\n",
        ": 0.268\n",
        "\n",
        "Modelo LASSO:\n",
        "\n",
        "Melhor\n",
        "ùëÖ\n",
        "2\n",
        ": 0.268\n",
        "\n",
        "Modelo Stepwise:\n",
        "\n",
        "ùëÖ\n",
        "2\n",
        ": 0.155\n",
        "\n",
        "Modelo Ridge (com transforma√ß√µes):\n",
        "\n",
        "Melhor\n",
        "ùëÖ\n",
        "2\n",
        ": 0.307\n",
        "\n",
        "Conclus√£o\n",
        "Com base nos resultados, o modelo Ridge com transforma√ß√µes apresentou o melhor desempenho, com um\n",
        "ùëÖ\n",
        "2\n",
        " de 0.307. Isso demonstra que aplicar transforma√ß√µes logar√≠tmicas e gerar intera√ß√µes entre as vari√°veis pode ajudar a melhorar a precis√£o do modelo."
      ],
      "metadata": {
        "id": "8szT6XoB2Dac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "\n",
        "# Criar e treinar a √°rvore de regress√£o\n",
        "tree_model = DecisionTreeRegressor(random_state=42)\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previs√µes na base de teste\n",
        "y_pred_tree = tree_model.predict(X_test)\n",
        "\n",
        "# Avaliar o modelo com o R¬≤\n",
        "r2_tree = r2_score(y_test, y_pred_tree)\n",
        "print(f'R¬≤ Score com √Årvore de Regress√£o: {r2_tree}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1iRhey02fuq",
        "outputId": "94bc8161-0bbb-4bcf-db73-5ed7df428208"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R¬≤ Score com √Årvore de Regress√£o: 0.11752192183511612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando os resultados, observamos que a √°rvore de regress√£o n√£o superou os outros modelos, apresentando um\n",
        "ùëÖ\n",
        "2\n",
        " de aproximadamente 0.118. Aqui est√£o os resultados finais:\n",
        "\n",
        "Compara√ß√£o dos Resultados\n",
        "Modelo Ridge (sem transforma√ß√µes):\n",
        "\n",
        "Melhor\n",
        "ùëÖ\n",
        "2\n",
        ": 0.268\n",
        "\n",
        "Modelo LASSO:\n",
        "\n",
        "Melhor\n",
        "ùëÖ\n",
        "2\n",
        ": 0.268\n",
        "\n",
        "Modelo Stepwise:\n",
        "\n",
        "ùëÖ\n",
        "2\n",
        ": 0.155\n",
        "\n",
        "Modelo Ridge (com transforma√ß√µes):\n",
        "\n",
        "Melhor\n",
        "ùëÖ\n",
        "2\n",
        ": 0.307\n",
        "\n",
        "√Årvore de Regress√£o:\n",
        "\n",
        "ùëÖ\n",
        "2\n",
        ": 0.118\n",
        "\n",
        "Conclus√£o\n",
        "O modelo Ridge com transforma√ß√µes permanece como o melhor, com um\n",
        "ùëÖ\n",
        "2\n",
        " de 0.307, superando os outros m√©todos, incluindo a √°rvore de regress√£o."
      ],
      "metadata": {
        "id": "z_b8a2RL2wx7"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}